---

title: Pytorch Errors


keywords: fastai
sidebar: home_sidebar

summary: "All the possible errors that fastdebug can support and verbosify involving Pytorch"
description: "All the possible errors that fastdebug can support and verbosify involving Pytorch"
nb_path: "00_error.torch.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_error.torch.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/mnt/d/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() &gt; 0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Errors">Errors<a class="anchor-link" href="#Errors"> </a></h2><p>While some errrors are specifically designed for the <a href="https://docs.fast.ai">fastai</a> library, the general idea still holds true in raw <code>Pytorch</code> as well.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="device_error" class="doc_header"><code>device_error</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L14" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>device_error</code>(<strong><code>e</code></strong>:<code>Exception</code>, <strong><code>a</code></strong>:<code>str</code>, <strong><code>b</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Verbose error for if <code>a</code> and <code>b</code> are on different devices
Should be used when checking if a model is on the same device, or two tensors</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The device error provides a much more readable error when <code>a</code> and <code>b</code> were on two different devices. An situation is below:</p>
<div class="highlight"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="n">device_error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="s1">&#39;Input type&#39;</span><span class="p">,</span> <span class="s1">&#39;Model weights&#39;</span><span class="p">)</span>
</pre></div>
<p>And our new log:</p>
<div class="highlight"><pre><span></span>---------------------------------------------------------------------------
RuntimeError                              Traceback <span class="o">(</span>most recent call last<span class="o">)</span>
&lt;ipython-input-28-981e0ace9c38&gt; <span class="k">in</span> &lt;module&gt;<span class="o">()</span>
      <span class="m">2</span>     model<span class="o">(</span>x<span class="o">)</span>
      <span class="m">3</span> except Exception as e:
----&gt; <span class="m">4</span>     device_error<span class="o">(</span>e, <span class="s1">&#39;Input type&#39;</span>, <span class="s1">&#39;Model weights&#39;</span><span class="o">)</span>

<span class="m">10</span> frames
/usr/local/lib/python3.7/dist-packages/torch/tensor.py <span class="k">in</span> __torch_function__<span class="o">(</span>cls, func, types, args, kwargs<span class="o">)</span>
    <span class="m">993</span> 
    <span class="m">994</span>         with _C.DisableTorchFunction<span class="o">()</span>:
--&gt; <span class="m">995</span>             <span class="nv">ret</span> <span class="o">=</span> func<span class="o">(</span>*args, **kwargs<span class="o">)</span>
    <span class="m">996</span>             <span class="k">return</span> _convert<span class="o">(</span>ret, cls<span class="o">)</span>
    <span class="m">997</span> 

RuntimeError: Mismatch between weight types

Input <span class="nb">type</span> has type:         <span class="o">(</span>torch.cuda.FloatTensor<span class="o">)</span>
Model weights have type:     <span class="o">(</span>torch.FloatTensor<span class="o">)</span>

Both should be the same.
</pre></div>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="hook_fn" class="doc_header"><code>hook_fn</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L27" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>hook_fn</code>(<strong><code>m</code></strong>, <strong><code>i</code></strong>)</p>
</blockquote>
<p>Simple hook fn to return the layer</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="PreHook" class="doc_header"><code>class</code> <code>PreHook</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L32" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>PreHook</code>(<strong><code>m</code></strong>, <strong><code>hook_func</code></strong>, <strong><code>is_forward</code></strong>=<em><code>True</code></em>, <strong><code>detach</code></strong>=<em><code>True</code></em>, <strong><code>cpu</code></strong>=<em><code>False</code></em>, <strong><code>gather</code></strong>=<em><code>False</code></em>) :: <code>Hook</code></p>
</blockquote>
<p>Creates and registers a hook on <code>m</code> with <code>hook_func</code> as a forward pre_hook</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ForwardHooks" class="doc_header"><code>class</code> <code>ForwardHooks</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L47" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ForwardHooks</code>(<strong><code>ms</code></strong>, <strong><code>hook_func</code></strong>, <strong><code>is_forward</code></strong>=<em><code>True</code></em>, <strong><code>detach</code></strong>=<em><code>True</code></em>, <strong><code>cpu</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Create several forward-hooks on the modules in <code>ms</code> with <code>hook_func</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="hook_outputs" class="doc_header"><code>hook_outputs</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L53" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>hook_outputs</code>(<strong><code>modules</code></strong>, <strong><code>detach</code></strong>=<em><code>True</code></em>, <strong><code>cpu</code></strong>=<em><code>False</code></em>, <strong><code>grad</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Return <code>Hooks</code> that store activations of all <code>modules</code> in <code>self.stored</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By using forward hooks, we can locate our problem layers when they arrive rather than trying to figure out which one it is through a list of confusing errors.</p>
<p>For this tutorial and testing we'll purposefully write a broken model:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="layer_error" class="doc_header"><code>layer_error</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L58" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>layer_error</code>(<strong><code>e</code></strong>:<code>Exception</code>, <strong><code>model</code></strong>, <strong><code>inp</code></strong>)</p>
</blockquote>
<p>Verbose error for when there is a size mismatch between some input and the model.
<code>model</code> should be any torch model
<code>inp</code> is the input that went to the model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/fastdebug/error.torch.html#layer_error"><code>layer_error</code></a> can be used anywhere that you want to check that the inputs are right for some model.</p>
<p>Let's use our <code>m</code> model from earlier to show an example:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">m</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="n">layer_error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-110-94e440b55d00&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>     m<span class="ansi-blue-fg">(</span>inp<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 5</span><span class="ansi-red-fg">     </span>layer_error<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> m<span class="ansi-blue-fg">,</span> inp<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-109-afeff2797250&gt;</span> in <span class="ansi-cyan-fg">layer_error</span><span class="ansi-blue-fg">(e, model, inp)</span>
<span class="ansi-green-intense-fg ansi-bold">     15</span>         <span class="ansi-blue-fg">[</span>h<span class="ansi-blue-fg">.</span>remove<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> h <span class="ansi-green-fg">in</span> hooks<span class="ansi-blue-fg">.</span>hooks<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     16</span>         e<span class="ansi-blue-fg">.</span>args <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">f&#39;Size mismatch between input tensors and what the model expects\n{&#34;-&#34;*76}\nLayer: {layer}\nError: &gt; {args}&#39;</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">---&gt; 17</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">raise</span> e

<span class="ansi-green-fg">&lt;ipython-input-110-94e440b55d00&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> inp <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>rand<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">5</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span>m<span class="ansi-blue-fg">(</span>inp<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>     layer_error<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> m<span class="ansi-blue-fg">,</span> inp<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    421</span> 
<span class="ansi-green-intense-fg ansi-bold">    422</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 423</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_conv_forward<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>weight<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    424</span> 
<span class="ansi-green-intense-fg ansi-bold">    425</span> <span class="ansi-green-fg">class</span> Conv3d<span class="ansi-blue-fg">(</span>_ConvNd<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">_conv_forward</span><span class="ansi-blue-fg">(self, input, weight)</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>                             _pair(0), self.dilation, self.groups)
<span class="ansi-green-intense-fg ansi-bold">    419</span>         return F.conv2d(input, weight, self.bias, self.stride,
<span class="ansi-green-fg">--&gt; 420</span><span class="ansi-red-fg">                         self.padding, self.dilation, self.groups)
</span><span class="ansi-green-intense-fg ansi-bold">    421</span> 
<span class="ansi-green-intense-fg ansi-bold">    422</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">RuntimeError</span>: Size mismatch between input tensors and what the model expects
----------------------------------------------------------------------------
Layer: Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
Error: &gt; Model expected 4-dimensional input for 4-dimensional weight [3, 3, 1, 1], but got 3-dimensional input of size [5, 2, 3] instead</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Much more readable!</p>

</div>
</div>
</div>
</div>
 

