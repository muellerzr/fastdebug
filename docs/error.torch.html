---

title: Pytorch Errors


keywords: fastai
sidebar: home_sidebar

summary: "All the possible errors that fastdebug can support and verbosify involving Pytorch"
description: "All the possible errors that fastdebug can support and verbosify involving Pytorch"
nb_path: "00_error.torch.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_error.torch.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Errors">Errors<a class="anchor-link" href="#Errors"> </a></h2><p>While some errrors are specifically designed for the <a href="https://docs.fast.ai">fastai</a> library, the general idea still holds true in raw <code>Pytorch</code> as well.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="device_error" class="doc_header"><code>device_error</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L10" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>device_error</code>(<strong><code>e</code></strong>:<code>Exception</code>, <strong><code>a</code></strong>:<code>str</code>, <strong><code>b</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Verbose error for if <code>a</code> and <code>b</code> are on different devices
Should be used when checking if a model is on the same device, or two tensors</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The device error provides a much more readable error when <code>a</code> and <code>b</code> were on two different devices. An situation is below:</p>
<div class="highlight"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="n">device_error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="s1">&#39;Input type&#39;</span><span class="p">,</span> <span class="s1">&#39;Model weights&#39;</span><span class="p">)</span>
</pre></div>
<p>And our new log:</p>
<div class="highlight"><pre><span></span>---------------------------------------------------------------------------
RuntimeError                              Traceback <span class="o">(</span>most recent call last<span class="o">)</span>
&lt;ipython-input-28-981e0ace9c38&gt; <span class="k">in</span> &lt;module&gt;<span class="o">()</span>
      <span class="m">2</span>     model<span class="o">(</span>x<span class="o">)</span>
      <span class="m">3</span> except Exception as e:
----&gt; <span class="m">4</span>     device_error<span class="o">(</span>e, <span class="s1">&#39;Input type&#39;</span>, <span class="s1">&#39;Model weights&#39;</span><span class="o">)</span>

<span class="m">10</span> frames
/usr/local/lib/python3.7/dist-packages/torch/tensor.py <span class="k">in</span> __torch_function__<span class="o">(</span>cls, func, types, args, kwargs<span class="o">)</span>
    <span class="m">993</span> 
    <span class="m">994</span>         with _C.DisableTorchFunction<span class="o">()</span>:
--&gt; <span class="m">995</span>             <span class="nv">ret</span> <span class="o">=</span> func<span class="o">(</span>*args, **kwargs<span class="o">)</span>
    <span class="m">996</span>             <span class="k">return</span> _convert<span class="o">(</span>ret, cls<span class="o">)</span>
    <span class="m">997</span> 

RuntimeError: Mismatch between weight types

Input <span class="nb">type</span> has type:         <span class="o">(</span>torch.cuda.FloatTensor<span class="o">)</span>
Model weights have type:     <span class="o">(</span>torch.FloatTensor<span class="o">)</span>

Both should be the same.
</pre></div>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_shape" class="doc_header"><code>get_shape</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L23" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_shape</code>(<strong><code>o</code></strong>:<code>str</code>)</p>
</blockquote>
<p>Finds the size of a string representation of a torch layer, and returns it</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All size errors in torch return a pattern of <code>expected [a, b, c] but got [d, e, f]</code>. <code>get_sz</code> only cares about that first part as we only want the size of the layer:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">size</span> <span class="o">=</span> <span class="n">get_sz</span><span class="p">(</span><span class="s2">&quot;Model expected [2, 2]&quot;</span><span class="p">)</span>
<span class="n">size</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_layer_by_shape" class="doc_header"><code>get_layer_by_shape</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L32" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_layer_by_shape</code>(<strong><code>m</code></strong>, <strong><code>weight_shape</code></strong>:<code>Size</code>)</p>
</blockquote>
<p>Grabs a layer in <code>m</code> of the same <code>shape</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Returns the layer number and the actual torch layer in some model <code>m</code> so long as the shape matches.
An example is below:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">get_layer_by_shape</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(3, Linear(in_features=3, out_features=2, bias=True))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='Currently this does not account for if multiple layers are in the same model of the same shape. Ideally we&#8217;d use Hooks instead but wasn&#8217;t able to get this working. ' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="layer_error" class="doc_header"><code>layer_error</code><a href="https://github.com/muellerzr/fastdebug/tree/master/fastdebug/error/torch.py#L40" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>layer_error</code>(<strong><code>e</code></strong>:<code>Exception</code>, <strong><code>model</code></strong>)</p>
</blockquote>
<p>Verbose error for when there is a size mismatch between some input and the model. <code>model</code> should be any torch model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/fastdebug/error.torch.html#layer_error"><code>layer_error</code></a> can be used anywhere that you want to check that the inputs are right for some model.</p>
<p>Let's use our <code>m</code> model from earlier to show an example:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">m</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="n">layer_error</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-84-d4ab91131841&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>     m<span class="ansi-blue-fg">(</span>inp<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 5</span><span class="ansi-red-fg">     </span>layer_error<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> m<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-83-ca2dc02cfff4&gt;</span> in <span class="ansi-cyan-fg">layer_error</span><span class="ansi-blue-fg">(e, model)</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span>     i<span class="ansi-blue-fg">,</span> layer <span class="ansi-blue-fg">=</span> get_layer_by_shape<span class="ansi-blue-fg">(</span>model<span class="ansi-blue-fg">,</span> shape<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      9</span>     e<span class="ansi-blue-fg">.</span>args <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">f&#39;Size mismatch between input tensors and what the model expects\n\n{args}\n\tat layer {i}: {layer}&#39;</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">---&gt; 10</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">raise</span> e

<span class="ansi-green-fg">&lt;ipython-input-84-d4ab91131841&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> inp <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>rand<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">5</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span>m<span class="ansi-blue-fg">(</span>inp<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>     layer_error<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> m<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    421</span> 
<span class="ansi-green-intense-fg ansi-bold">    422</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 423</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_conv_forward<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>weight<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    424</span> 
<span class="ansi-green-intense-fg ansi-bold">    425</span> <span class="ansi-green-fg">class</span> Conv3d<span class="ansi-blue-fg">(</span>_ConvNd<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/mnt/d/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ansi-cyan-fg">_conv_forward</span><span class="ansi-blue-fg">(self, input, weight)</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>                             _pair(0), self.dilation, self.groups)
<span class="ansi-green-intense-fg ansi-bold">    419</span>         return F.conv2d(input, weight, self.bias, self.stride,
<span class="ansi-green-fg">--&gt; 420</span><span class="ansi-red-fg">                         self.padding, self.dilation, self.groups)
</span><span class="ansi-green-intense-fg ansi-bold">    421</span> 
<span class="ansi-green-intense-fg ansi-bold">    422</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">:</span> Tensor<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Tensor<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">RuntimeError</span>: Size mismatch between input tensors and what the model expects

Model expected 4-dimensional input for 4-dimensional weight [3, 3, 1, 1], but got 3-dimensional input of size [5, 2, 3] instead
	at layer 1: Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Much more readable!</p>

</div>
</div>
</div>
</div>
 

