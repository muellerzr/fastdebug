# AUTOGENERATED! DO NOT EDIT! File to edit: 00_error.torch.ipynb (unless otherwise specified).

__all__ = ['device_error', 'get_shape', 'get_layer_by_shape', 'layer_error']

# Cell
import torch
import re

# Cell
def device_error(e:Exception, a:str, b:str) -> Exception:
    """
    Verbose error for if `a` and `b` are on different devices
    Should be used when checking if a model is on the same device, or two tensors
    """
    inp, weight, _ = e.args[0].replace('( ', '').split(')')
    inp = inp.replace('Input type', f'{a} has type: \t\t')
    weight = weight.replace(' and weight type', f'{b} have type: \t')
    err = f'Mismatch between weight types\n\n{inp})\n{weight})\n\nBoth should be the same.'
    e.args = [err]
    raise e

# Cell
def get_shape(o:str) -> torch.Size:
    """
    Finds the size of a string representation of a torch layer, and returns it
    """
    m = re.findall(r'\[([0-9, +]+)\]', o)[0]
    shp = [int(i) for i in m.split(', ')]
    return torch.Size(shp)

# Cell
def get_layer_by_shape(m, weight_shape:torch.Size):
    "Grabs a layer in `m` of the same `shape`"
    for i, layer in enumerate(m.modules()):
        if hasattr(layer, 'weight'):
            if layer.weight.shape == weight_shape:
                return i, layer

# Cell
def layer_error(e:Exception, model) -> Exception:
    """
    Verbose error for when there is a size mismatch between some input and the model. `model` should be any torch model
    """
    args = e.args[0].replace("Expected", "Model expected")
    shape = get_shape(args)
    i, layer = get_layer_by_shape(model, shape)
    e.args = [f'Size mismatch between input tensors and what the model expects\n\n{args}\n\tat layer {i}: {layer}']
    raise e